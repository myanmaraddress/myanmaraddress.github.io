<!DOCTYPE html>
<html lang="zh-CN">

<head>
        <link rel="canonical" href="https://myanmaraddress.github.io/html/category/article-2832.htm" />
    <title>pytorch 自动构建任意层的深度神经网络(DNN) - Myanmar Address</title>
        <link rel="icon" href="/assets/addons/xcblog/img/myanmaraddress/favicon.ico" type="image/x-icon"/>
    <link href="/assets/addons/xcblog/css/myanmaraddress/bootstrap.css" rel="stylesheet" type="text/css" media="all">
    <!--theme-style-->
    <link href="/assets/addons/xcblog/css/myanmaraddress/style.css" rel="stylesheet" type="text/css" media="all">
    <!--//theme-style-->
    <link href="/assets/addons/xcblog/css/myanmaraddress/popuo-box.css" rel="stylesheet" type="text/css" media="all" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- script -->
    <script src="/assets/addons/xcblog/js/frontend/myanmaraddress/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/move-top.js"></script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/easing.js"></script>
    <link type="text/css" rel="stylesheet" href="/assets/addons/xcblog/css/myanmaraddress/jquery.mmenu.all.css" />
    <script type="text/javascript">
    $(window).load(function() {
        $('div.description').each(function() {
            $(this).css('display', 'block');
        });

        $('div.content-top-grid').hover(function() {
            $(this).children('.description').stop().fadeTo(500, 1);
        }, function() {
            $(this).children('.description').stop().fadeTo(500, 0);
        });

    });
    </script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/jquery.mmenu.js"></script>
    <script type="text/javascript">
    //	The menu on the left
    $(function() {
        $('nav#menu-left').mmenu();
    });
    </script>
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e4890e777e20237a4f5a0c3a6a01049c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body>
    <!--header-->
    <div class="header">
        <a class="navicon" href="#menu-left"> </a>
        <div class="container">
            <div class="header-matter">
                <h1>pytorch 自动构建任意层的深度神经网络(DNN)</h1>
                <p>
                    <a href="/">首页</a> / <a href="/html/category/">文章分类</a> / 正文
                </p>
            </div>
        </div>
                <nav id="menu-left">
            <ul>
                                <li><a href="/">首页</a></li>
                                <li><a href="/html/category/">文章分类</a></li>
                                <li>
                    <a href="#">关于</a>
                </li>
                <li>
                    <a href="#">联系</a>
                </li>
            </ul>
        </nav>
        <script type="text/javascript">
        jQuery(document).ready(function($) {
            $(".scroll").click(function(event) {
                event.preventDefault();
                $('html,body').animate({ scrollTop: $(this.hash).offset().top }, 1000);
            });
        });
        </script>
    </div>
    <div class="clearfix"> </div>
    <!--//header-->
    <!--content-->
    <div class="content">
        <!--our-news-->
        <div class="our-news" id="news">
            <div class="container">
                <div class="row">
                    <div class="col-md-9">
                        <div class="news">
                              				  				  				<div id="content_views" class="markdown_views prism-dracula"> <p>动手撸神经网络的代码，是大家常常遇到的问题。在设计自己的网络时，需要考虑网络大小，隐藏层层数，激活函数和参数初始化方法。最笨拙的方法就是固定下来，发生变化就要手动调整一次。这里介绍一种可以自动生生网络的方法，每次改变只需要调整一些参数，网络就会自动改变，大大提升了生产代码的效率。<br /> 参考链接：<br /> 1、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/qq_37385726/article/details/81740233"  rel="nofollow">Pytorch之搭建神经网络的四种方法</a><br /> 2、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/bigkaimyc/article/details/103939696"  rel="nofollow">Pytorch–1.使用Pytorch搭建一个简易的神经网络</a><br /> 3、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/zkk9527/article/details/88399176"  rel="nofollow">十分钟掌握Pytorch搭建神经网络的流程</a><br /> 4、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/jining11/article/details/88728052"  rel="nofollow">使用pytorch搭建神经网络</a><br /> 5、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/weixin_42263486/article/details/108279905"  rel="nofollow">PyTorch使用教程-PyTorch构建神经网络(下)</a><br /> 6、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/luo3300612/article/details/97675312"  rel="nofollow">Pytorch 默认参数初始化</a><br /> 7、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://www.jianshu.com/p/1a1339c4acd7"  rel="nofollow">Pytorch中常用的四种优化器SGD、Momentum、RMSProp、Adam</a></p> <pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span> <span class="token triple-quoted-string string">""" Created on 2021.06.18 @author: LXA """</span> <span class="token keyword">import</span> torch <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> tn <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> tnf <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parameter <span class="token keyword">import</span> Parameter <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np  <span class="token keyword">class</span> <span class="token class-name">my_actFunc</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> actName<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>my_actFunc<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actName <span class="token operator">=</span> actName      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">if</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'relu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'leaky_relu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>leaky_relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'tanh'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'srelu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span><span class="token operator">*</span>tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'elu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>elu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'sin'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'sigmoid'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">else</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> x_input         <span class="token keyword">return</span> out_x          <span class="token comment"># ----------------dense net(constructing NN and initializing weights and bias )------------</span> <span class="token keyword">class</span> <span class="token class-name">Pure_DenseNet</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token triple-quoted-string string">"""     Args:         indim: the dimension for input data         outdim: the dimension for output         hidden_units: the number of  units for hidden layer, a list or a tuple         name2Model: the name of using DNN type, DNN , ScaleDNN or FourierDNN         actName2in: the name of activation function for input layer         actName: the name of activation function for hidden layer         actName2out: the name of activation function for output layer         scope2W: the namespace of weight         scope2B: the namespace of bias     """</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> outdim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_units<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name2Model<span class="token operator">=</span><span class="token string">'DNN'</span><span class="token punctuation">,</span> actName2in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> actName<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                  actName2out<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> scope2W<span class="token operator">=</span><span class="token string">'Weight'</span><span class="token punctuation">,</span> scope2B<span class="token operator">=</span><span class="token string">'Bias'</span><span class="token punctuation">,</span> type2float<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">,</span> to_gpu<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> gpu_no<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>Pure_DenseNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>indim <span class="token operator">=</span> indim         self<span class="token punctuation">.</span>outdim <span class="token operator">=</span> outdim         self<span class="token punctuation">.</span>hidden_units <span class="token operator">=</span> hidden_units         self<span class="token punctuation">.</span>name2Model <span class="token operator">=</span> name2Model         self<span class="token punctuation">.</span>actFunc_in <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName2in<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actFunc <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actFunc_out <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName2out<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers <span class="token operator">=</span> tn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>          input_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>indim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>input_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>input_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_layer<span class="token punctuation">)</span>          <span class="token keyword">for</span> i_layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_units<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>             hidden_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span>i_layer<span class="token punctuation">]</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span>i_layer<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>             tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>             tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>             self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">)</span>          out_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>outdim<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>out_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>out_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out_layer<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">get_regular_sum2WB</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> regular_model<span class="token operator">=</span><span class="token string">'L2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         regular_w <span class="token operator">=</span> <span class="token number">0</span>         regular_b <span class="token operator">=</span> <span class="token number">0</span>         <span class="token keyword">if</span> regular_model <span class="token operator">==</span> <span class="token string">'L1'</span><span class="token punctuation">:</span>             <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">:</span>                 regular_w <span class="token operator">=</span> regular_w <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>                 regular_b <span class="token operator">=</span> regular_b <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token keyword">elif</span> regular_model <span class="token operator">==</span> <span class="token string">'L2'</span><span class="token punctuation">:</span>             <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">:</span>                 regular_w <span class="token operator">=</span> regular_w <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>                 regular_b <span class="token operator">=</span> regular_b <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> regular_w<span class="token punctuation">,</span> regular_b      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token comment"># ------ dealing with the input data ---------------</span>         dense_in <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>         H <span class="token operator">=</span> dense_in<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>         H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc_in<span class="token punctuation">(</span>H<span class="token punctuation">)</span>          <span class="token comment">#  ---resnet(one-step skip connection for two consecutive layers if have equal neurons）---</span>         hidden_record <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>         <span class="token keyword">for</span> i_layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>             H_pre <span class="token operator">=</span> H             dense_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span>i_layer<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>             H <span class="token operator">=</span> dense_layer<span class="token punctuation">(</span>H<span class="token punctuation">)</span>             H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc<span class="token punctuation">(</span>H<span class="token punctuation">)</span>             <span class="token keyword">if</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span>i_layer <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> hidden_record<span class="token punctuation">:</span>                 H <span class="token operator">=</span> H <span class="token operator">+</span> H_pre             hidden_record <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span>i_layer <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>          dense_out <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>         H <span class="token operator">=</span> dense_out<span class="token punctuation">(</span>H<span class="token punctuation">)</span>         H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc_out<span class="token punctuation">(</span>H<span class="token punctuation">)</span>         <span class="token keyword">return</span> H   <span class="token keyword">class</span> <span class="token class-name">DNN_test</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim_in<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> dim_out<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_layers<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name2Model<span class="token operator">=</span><span class="token string">'DNN'</span><span class="token punctuation">,</span> actName_in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                  actName_hidden<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> actName_out<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> use_gpu<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> no2gpu<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>DNN_test<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>name2Model <span class="token operator">=</span> name2Model         self<span class="token punctuation">.</span>dim_in <span class="token operator">=</span> dim_in         self<span class="token punctuation">.</span>dim_out <span class="token operator">=</span> dim_out         <span class="token keyword">if</span> name2Model <span class="token operator">==</span> <span class="token string">'DNN'</span><span class="token punctuation">:</span>             self<span class="token punctuation">.</span>DNN <span class="token operator">=</span> Pure_DenseNet<span class="token punctuation">(</span>indim<span class="token operator">=</span>dim_in<span class="token punctuation">,</span> outdim<span class="token operator">=</span>dim_out<span class="token punctuation">,</span> hidden_units<span class="token operator">=</span>hidden_layers<span class="token punctuation">,</span> name2Model<span class="token operator">=</span>name2Model<span class="token punctuation">,</span>                                      actName2in<span class="token operator">=</span>actName_in<span class="token punctuation">,</span> actName<span class="token operator">=</span>actName_hidden<span class="token punctuation">,</span> actName2out<span class="token operator">=</span>actName_out<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         out <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">(</span>x_input<span class="token punctuation">,</span> scale<span class="token operator">=</span>freq<span class="token punctuation">)</span>         <span class="token keyword">return</span> out      <span class="token keyword">def</span> <span class="token function">get_sum2wB</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">if</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'DNN'</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'Scale_DNN'</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'Fourier_DNN'</span><span class="token punctuation">:</span>             sum2WB <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">.</span>get_regular_sum2WB<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> sum2WB      <span class="token keyword">def</span> <span class="token function">cal_l2loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> y_input<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         out <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">(</span>x_input<span class="token punctuation">,</span> scale<span class="token operator">=</span>freq<span class="token punctuation">)</span>         squre_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>y_input <span class="token operator">-</span> out<span class="token punctuation">,</span> y_input <span class="token operator">-</span> out<span class="token punctuation">)</span>         loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>squre_loss<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> loss<span class="token punctuation">,</span> out   <span class="token keyword">def</span> <span class="token function">test_DNN</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     batch_size <span class="token operator">=</span> <span class="token number">10</span>     dim_in <span class="token operator">=</span> <span class="token number">2</span>     dim_out <span class="token operator">=</span> <span class="token number">1</span>     hidden_list <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>     freq <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>     model_name <span class="token operator">=</span> <span class="token string">'DNN'</span>     init_lr <span class="token operator">=</span> <span class="token number">0.01</span>     max_it <span class="token operator">=</span> <span class="token number">10000</span>     with_gpu <span class="token operator">=</span> <span class="token boolean">True</span>      model <span class="token operator">=</span> DNN_test<span class="token punctuation">(</span>dim_in<span class="token operator">=</span>dim_in<span class="token punctuation">,</span> dim_out<span class="token operator">=</span>dim_out<span class="token punctuation">,</span> hidden_layers<span class="token operator">=</span>hidden_list<span class="token punctuation">,</span> name2Model<span class="token operator">=</span>model_name<span class="token punctuation">,</span> actName_in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                 actName_hidden<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> use_gpu<span class="token operator">=</span>with_gpu<span class="token punctuation">,</span> no2gpu<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> with_gpu<span class="token punctuation">:</span>         model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      params2Net <span class="token operator">=</span> model<span class="token punctuation">.</span>DNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 定义优化方法，并给定初始学习率</span>     <span class="token comment"># optimizer = torch.optim.SGD(params2Net, lr=init_lr)                     # SGD</span>     <span class="token comment"># optimizer = torch.optim.SGD(params2Net, lr=init_lr, momentum=0.8)       # momentum</span>     <span class="token comment"># optimizer = torch.optim.RMSprop(params2Net, lr=init_lr, alpha=0.95)     # RMSProp</span>     optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>params2Net<span class="token punctuation">,</span> lr<span class="token operator">=</span>init_lr<span class="token punctuation">)</span>  <span class="token comment"># Adam</span>      <span class="token comment"># 定义更新学习率的方法</span>     <span class="token comment"># scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)</span>     <span class="token comment"># scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))</span>     scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.995</span><span class="token punctuation">)</span>     arr2epoch <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     arr2loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     arr2lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     <span class="token keyword">for</span> i_epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_it<span class="token punctuation">)</span><span class="token punctuation">:</span>         x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> dim_in<span class="token punctuation">)</span>         x <span class="token operator">=</span> x<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>         torch_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>         y <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> newshape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         torch_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span>         <span class="token keyword">if</span> with_gpu<span class="token punctuation">:</span>             torch_x <span class="token operator">=</span> torch_x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             torch_y <span class="token operator">=</span> torch_y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          loss<span class="token punctuation">,</span> prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>cal_l2loss<span class="token punctuation">(</span>x_input<span class="token operator">=</span>torch_x<span class="token punctuation">,</span> freq<span class="token operator">=</span>freq<span class="token punctuation">,</span> y_input<span class="token operator">=</span>torch_y<span class="token punctuation">)</span>         sum2wb <span class="token operator">=</span> model<span class="token punctuation">.</span>get_sum2wB<span class="token punctuation">(</span><span class="token punctuation">)</span>          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 求导前先清零, 只要在下一次求导前清零即可</span>         loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 求偏导</span>         optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 更新参数</span>         scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">if</span> i_epoch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>             <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'i_epoch --- loss:'</span><span class="token punctuation">,</span> i_epoch<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># print("第%d个epoch的学习率：%f" % (i_epoch, optimizer.param_groups[0]['lr']))</span>             arr2loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             arr2lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>     ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>arr2loss<span class="token punctuation">,</span> <span class="token string">'b-.'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch/100'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>fontsize<span class="token operator">=</span><span class="token number">18</span><span class="token punctuation">)</span>     ax<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># plt.cla()</span>     <span class="token comment"># plt.plot(x[:, 0], x[:, 1], y, 'b*')</span>     <span class="token comment"># plt.show()</span>   <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>     test_DNN<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre> </p></div> 			                        </div>

                        <div class="col-md-12 mt-5">
                                                        <p>上一个：<a href="/html/category/article-2831.htm">kerberos kafka 问题解决</a></p>
                                                        <p>下一个：<a href="/html/category/article-3129.htm">Vue结合ElementUI上传Base64编码后的图片实例_vue.js</a></p>
                                                    </div>

                                                <div class="panel panel-default mt-5">
                            <div class="panel-heading">
                                <h3 class="m-0">推荐文章</h3>
                            </div>
                            <div class="panel-body">
                                <ul class="p-0 x-0">
                                                                        <li class="py-2"><a href="/html/category/article-1637.htm">Java基础之浅谈异常与了解断言</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1298.htm">利用Redis实现防止接口重复提交功能</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1292.htm">Flutter实现心动的动画特效_Android</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1270.htm">C# 实现登录并跳转界面</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1234.htm">java中Date与LocalDate、LocalDate、LocalDateTime互相转化</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1221.htm">自定义全局异常处理机制</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1162.htm">Python实用技法第11篇：找出序列中出现次数最多的元素</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1105.htm">SpringCloud 之 Config服务配置 详解</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1099.htm">C++ 标准输入、输出流</a></li>
                                                                        <li class="py-2"><a href="/html/category/article-1079.htm">PHP类抽象</a></li>
                                                                    </ul>
                            </div>
                        </div>
                                            </div>
                    <div class="col-md-3">
                    	<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/html/category/article-3130.htm" title="python和hive结合使用">python和hive结合使用</a></li>
                        <li class="py-2"><a href="/html/category/article-1350.htm" title="小程序怎么自定义导航栏，导航栏放图片、设置高度">小程序怎么自定义导航栏，导航栏放图片、设置高度</a></li>
                        <li class="py-2"><a href="/html/category/article-3431.htm" title="Jackson 枚举序列化/反序列化">Jackson 枚举序列化/反序列化</a></li>
                        <li class="py-2"><a href="/html/category/article-1297.htm" title="vue2设置保存自动执行run lint配置步骤">vue2设置保存自动执行run lint配置步骤</a></li>
                        <li class="py-2"><a href="/html/category/article-1961.htm" title="python自动化测试工具selenium使用指南">python自动化测试工具selenium使用指南</a></li>
                        <li class="py-2"><a href="/html/category/article-1301.htm" title="Uniapp-远离回调callback请使用await、async">Uniapp-远离回调callback请使用await、async</a></li>
                        <li class="py-2"><a href="/html/category/article-1312.htm" title="有关动态规划的相关优化思想_在线工具">有关动态规划的相关优化思想_在线工具</a></li>
                        <li class="py-2"><a href="/html/category/article-1934.htm" title="朴素贝叶斯算法详解">朴素贝叶斯算法详解</a></li>
                        <li class="py-2"><a href="/html/category/article-1293.htm" title="基于Spring接口，集成Caffeine+Redis两级缓存">基于Spring接口，集成Caffeine+Redis两级缓存</a></li>
                        <li class="py-2"><a href="/html/category/article-2248.htm" title="vue 详情页返回列表，过滤查询条件保留">vue 详情页返回列表，过滤查询条件保留</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">58</span> <a href="/html/date/2024-06/" title="2024-06 归档">2024-06</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-05/" title="2024-05 归档">2024-05</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">60</span> <a href="/html/date/2024-04/" title="2024-04 归档">2024-04</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-03/" title="2024-03 归档">2024-03</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">50</span> <a href="/html/date/2024-02/" title="2024-02 归档">2024-02</a></h4>
            </li>
                    </ul>
    </div>
</div>

                    </div>
                </div>
            </div>
        </div>
    </div>
    <!--//content-->
        <!--footer-->
    <div class="footer">
        <div class="container">
            <p>
                Myanmar Address 版权所有
                <br />
                Powered by WordPress
            </p>
        </div>
    </div>
    <script>
    $(function() {
        $('.js_to').click(function(){
            var url = $(this).data('url');
            var code = $(this).data('code');
            url += code;

            window.open(url);
        })
    });
    </script>
</body>

</html>