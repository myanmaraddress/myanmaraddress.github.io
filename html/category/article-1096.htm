<!DOCTYPE html>
<html lang="zh-CN">

<head>
        <link rel="canonical" href="https://myanmaraddress.github.io/html/category/article-1096.htm" />
    <title>kafka消费者执行异常重复消费_4.Kafka消费者详解 - Myanmar Address</title>
        <link rel="icon" href="/assets/addons/xcblog/img/myanmaraddress/favicon.ico" type="image/x-icon"/>
    <link href="/assets/addons/xcblog/css/myanmaraddress/bootstrap.css" rel="stylesheet" type="text/css" media="all">
    <!--theme-style-->
    <link href="/assets/addons/xcblog/css/myanmaraddress/style.css" rel="stylesheet" type="text/css" media="all">
    <!--//theme-style-->
    <link href="/assets/addons/xcblog/css/myanmaraddress/popuo-box.css" rel="stylesheet" type="text/css" media="all" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- script -->
    <script src="/assets/addons/xcblog/js/frontend/myanmaraddress/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/move-top.js"></script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/easing.js"></script>
    <link type="text/css" rel="stylesheet" href="/assets/addons/xcblog/css/myanmaraddress/jquery.mmenu.all.css" />
    <script type="text/javascript">
    $(window).load(function() {
        $('div.description').each(function() {
            $(this).css('display', 'block');
        });

        $('div.content-top-grid').hover(function() {
            $(this).children('.description').stop().fadeTo(500, 1);
        }, function() {
            $(this).children('.description').stop().fadeTo(500, 0);
        });

    });
    </script>
    <script type="text/javascript" src="/assets/addons/xcblog/js/frontend/myanmaraddress/jquery.mmenu.js"></script>
    <script type="text/javascript">
    //	The menu on the left
    $(function() {
        $('nav#menu-left').mmenu();
    });
    </script>
    <script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e4890e777e20237a4f5a0c3a6a01049c";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body>
    <!--header-->
    <div class="header">
        <a class="navicon" href="#menu-left"> </a>
        <div class="container">
            <div class="header-matter">
                <h1>kafka消费者执行异常重复消费_4.Kafka消费者详解</h1>
                <p>
                    <a href="/">首页</a> / <a href="/html/category/">文章分类</a> / 正文
                </p>
            </div>
        </div>
                <nav id="menu-left">
            <ul>
                                <li><a href="/">首页</a></li>
                                <li><a href="/html/category/">文章分类</a></li>
                                <li>
                    <a href="#">关于</a>
                </li>
                <li>
                    <a href="#">联系</a>
                </li>
            </ul>
        </nav>
        <script type="text/javascript">
        jQuery(document).ready(function($) {
            $(".scroll").click(function(event) {
                event.preventDefault();
                $('html,body').animate({ scrollTop: $(this.hash).offset().top }, 1000);
            });
        });
        </script>
    </div>
    <div class="clearfix"> </div>
    <!--//header-->
    <!--content-->
    <div class="content">
        <!--our-news-->
        <div class="our-news" id="news">
            <div class="container">
                <div class="row">
                    <div class="col-md-9">
                        <div class="news">
                              				  				  				<div id="content_views" class="htmledit_views"> <div class="._5ce-wx-style" style="font-size:16px;"> <div class="rich_media_content" id="js_content"> <h2><span style="font-weight:bold;">一、消费者和消费者群组</span></h2> <p>在 Kafka 中，消费者通常是消费者群组的一部分，多个消费者群组共同读取同一个主题时，彼此之间互不影响。Kafka 之所以要引入消费者群组这个概念是因为 Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS ，或者进行耗时的计算，在这些情况下，单个消费者无法跟上数据生成的速度。此时可以增加更多的消费者，让它们分担负载，分别处理部分分区的消息，这就是 Kafka 实现横向伸缩的主要手段。</p> <p><img decoding="async" src="http://img.555519.xyz/uploads/20230108/706f94d7d920b204f8dc4ba23df8869c.jpg" alt="kafka消费者执行异常重复消费_4.Kafka消费者详解"></p> <p>需要注意的是：同一个分区只能被同一个消费者群组里面的一个消费者读取，不可能存在同一个分区被同一个消费者群里多个消费者共同读取的情况，如图：</p> <p><img decoding="async" src="http://img.555519.xyz/uploads/20230108/e0f91302fb2fa9f960de5d7299715de9.jpg" alt="kafka消费者执行异常重复消费_4.Kafka消费者详解"></p> <p>可以看到即便消费者 Consumer5 空闲了，但是也不会去读取任何一个分区的数据，这同时也提醒我们在使用时应该合理设置消费者的数量，以免造成闲置和额外开销。</p> <h2><span style="font-weight:bold;">二、分区再均衡</span></h2> <p>因为群组里的消费者共同读取主题的分区，所以当一个消费者被关闭或发生崩溃时，它就离开了群组，原本由它读取的分区将由群组里的其他消费者来读取。同时在主题发生变化时 ， 比如添加了新的分区，也会发生分区与消费者的重新分配，分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。正是因为再均衡，所以消费费者群组才能保证高可用性和伸缩性。</p> <p>消费者通过向群组协调器所在的 broker 发送心跳来维持它们和群组的从属关系以及它们对分区的所有权。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发再均衡。</p> <h2><span style="font-weight:bold;">三、创建Kafka消费者</span></h2> <p>在创建消费者的时候以下以下三个选项是必选的：</p> <ul> <li> <p><strong>bootstrap.servers</strong> ：指定 broker 的地址清单，清单里不需要包含所有的 broker 地址，生产者会从给定的 broker 里查找 broker 的信息。不过建议至少要提供两个 broker 的信息作为容错；</p> </li> <li> <p><strong>key.deserializer</strong> ：指定键的反序列化器；</p> </li> <li> <p><strong>value.deserializer</strong> ：指定值的反序列化器。</p> </li> </ul> <p>除此之外你还需要指明你需要想订阅的主题，可以使用如下两个 API :</p> <ul> <li> <p><strong>consumer.subscribe(Collection&lt;String&gt; topics)</strong> &nbsp;：指明需要订阅的主题的集合；</p> </li> <li> <p><strong>consumer.subscribe(Pattern pattern)</strong> &nbsp;：使用正则来匹配需要订阅的集合。</p> </li> </ul> <p>最后只需要通过轮询 API(<code>poll</code>) 向服务器定时请求数据。一旦消费者订阅了主题，轮询就会处理所有的细节，包括群组协调、分区再均衡、发送心跳和获取数据，这使得开发者只需要关注从分区返回的数据，然后进行业务处理。示例如下：</p> <pre><code>String topic = "Hello-Kafka";String group = "group1";Properties props = new Properties();props.put("bootstrap.servers", "hadoop001:9092");/*指定分组 ID*/props.put("group.id", group);props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);/*订阅主题 (s)*/consumer.subscribe(Collections.singletonList(topic));try {<!-- --> &nbsp; &nbsp;while (true) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;/*轮询获取数据*/ &nbsp; &nbsp; &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp; &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;System.out.printf("topic = %s,partition = %d, key = %s, value = %s, offset = %d,\n", &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; record.topic(), record.partition(), record.key(), record.value(), record.offset()); &nbsp; &nbsp; &nbsp;  } &nbsp;  }} finally {<!-- --> &nbsp; &nbsp;consumer.close();}</code></pre> <blockquote> <p>本篇文章的所有示例代码可以从 Github 上进行下载：kafka-basis</p> </blockquote> <h2><span style="font-weight:bold;">三、 自动提交偏移量</span></h2> <h3><span style="font-weight:bold;">3.1 偏移量的重要性</span></h3> <p>Kafka 的每一条消息都有一个偏移量属性，记录了其在分区中的位置，偏移量是一个单调递增的整数。消费者通过往一个叫作 <code>＿consumer_offset</code> 的特殊主题发送消息，消息里包含每个分区的偏移量。如果消费者一直处于运行状态，那么偏移量就没有什么用处。不过，如果有消费者退出或者新分区加入，此时就会触发再均衡。完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。因为这个原因，所以如果不能正确提交偏移量，就可能会导致数据丢失或者重复出现消费，比如下面情况：</p> <ul> <li> <p>如果提交的偏移量小于客户端处理的最后一个消息的偏移量 ，那么处于两个偏移量之间的消息就会被重复消费；</p> </li> <li> <p>如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。</p> </li> </ul> <h3><span style="font-weight:bold;">3.2 自动提交偏移量</span></h3> <p>Kafka 支持自动提交和手动提交偏移量两种方式。这里先介绍比较简单的自动提交：</p> <p>只需要将消费者的 <code>enable.auto.commit</code> 属性配置为 <code>true</code> 即可完成自动提交的配置。此时每隔固定的时间，消费者就会把 <code>poll()</code> 方法接收到的最大偏移量进行提交，提交间隔由 <code>auto.commit.interval.ms</code> 属性进行配置，默认值是 5s。</p> <p>使用自动提交是存在隐患的，假设我们使用默认的 5s 提交时间间隔，在最近一次提交之后的 3s 发生了再均衡，再均衡之后，消费者从最后一次提交的偏移量位置开始读取消息。这个时候偏移量已经落后了 3s ，所以在这 3s 内到达的消息会被重复处理。可以通过修改提交时间间隔来更频繁地提交偏移量，减小可能出现重复消息的时间窗，不过这种情况是无法完全避免的。基于这个原因，Kafka 也提供了手动提交偏移量的 API，使得用户可以更为灵活的提交偏移量。</p> <h2><span style="font-weight:bold;">四、手动提交偏移量</span></h2> <p>用户可以通过将 <code>enable.auto.commit</code> 设为 <code>false</code>，然后手动提交偏移量。基于用户需求手动提交偏移量可以分为两大类：</p> <ul> <li> <p>手动提交当前偏移量：即手动提交当前轮询的最大偏移量；</p> </li> <li> <p>手动提交固定偏移量：即按照业务需求，提交某一个固定的偏移量。</p> </li> </ul> <p>而按照 Kafka API，手动提交偏移量又可以分为同步提交和异步提交。</p> <h3><span style="font-weight:bold;">4.1 同步提交</span></h3> <p>通过调用 <code>consumer.commitSync()</code> 来进行同步提交，不传递任何参数时提交的是当前轮询的最大偏移量。</p> <pre><code>while (true) {<!-- --> &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;System.out.println(record); &nbsp;  } &nbsp; &nbsp;/*同步提交*/ &nbsp; &nbsp;consumer.commitSync();}</code></pre> <p>如果某个提交失败，同步提交还会进行重试，这可以保证数据能够最大限度提交成功，但是同时也会降低程序的吞吐量。基于这个原因，Kafka 还提供了异步提交的 API。</p> <h3><span style="font-weight:bold;">4.2 异步提交</span></h3> <p>异步提交可以提高程序的吞吐量，因为此时你可以尽管请求数据，而不用等待 Broker 的响应。代码如下：</p> <pre><code>while (true) {<!-- --> &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;System.out.println(record); &nbsp;  } &nbsp; &nbsp;/*异步提交并定义回调*/ &nbsp; &nbsp;consumer.commitAsync(new OffsetCommitCallback() {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;@Override &nbsp; &nbsp; &nbsp; &nbsp;public void onComplete(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, Exception exception) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;if (exception != null) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; System.out.println("错误处理"); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; offsets.forEach((x, y) -&gt; System.out.printf("topic = %s,partition = %d, offset = %s \n", &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;x.topic(), x.partition(), y.offset())); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  } &nbsp; &nbsp; &nbsp;  } &nbsp;  });}</code></pre> <p>异步提交存在的问题是，在提交失败的时候不会进行自动重试，实际上也不能进行自动重试。假设程序同时提交了 200 和 300 的偏移量，此时 200 的偏移量失败的，但是紧随其后的 300 的偏移量成功了，此时如果重试就会存在 200 覆盖 300 偏移量的可能。同步提交就不存在这个问题，因为在同步提交的情况下，300 的提交请求必须等待服务器返回 200 提交请求的成功反馈后才会发出。基于这个原因，某些情况下，需要同时组合同步和异步两种提交方式。</p> <blockquote> <p>注：虽然程序不能在失败时候进行自动重试，但是我们是可以手动进行重试的，你可以通过一个 Map offsets 来维护你提交的每个分区的偏移量，然后当失败时候，你可以判断失败的偏移量是否小于你维护的同主题同分区的最后提交的偏移量，如果小于则代表你已经提交了更大的偏移量请求，此时不需要重试，否则就可以进行手动重试。</p> </blockquote> <h3><span style="font-weight:bold;">4.3 &nbsp;同步加异步提交</span></h3> <p>下面这种情况，在正常的轮询中使用异步提交来保证吞吐量，但是因为在最后即将要关闭消费者了，所以此时需要用同步提交来保证最大限度的提交成功。</p> <pre><code>try {<!-- --> &nbsp; &nbsp;while (true) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp; &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;System.out.println(record); &nbsp; &nbsp; &nbsp;  } &nbsp; &nbsp; &nbsp; &nbsp;// 异步提交 &nbsp; &nbsp; &nbsp; &nbsp;consumer.commitAsync(); &nbsp;  }} catch (Exception e) {<!-- --> &nbsp; &nbsp;e.printStackTrace();} finally {<!-- --> &nbsp; &nbsp;try {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;// 因为即将要关闭消费者，所以要用同步提交保证提交成功 &nbsp; &nbsp; &nbsp; &nbsp;consumer.commitSync(); &nbsp;  } finally {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;consumer.close(); &nbsp;  }}</code></pre> <h3><span style="font-weight:bold;">4.4 提交特定偏移量</span></h3> <p>在上面同步和异步提交的 API 中，实际上我们都没有对 commit 方法传递参数，此时默认提交的是当前轮询的最大偏移量，如果你需要提交特定的偏移量，可以调用它们的重载方法。</p> <pre><code>/*同步提交特定偏移量*/commitSync(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets) /*异步提交特定偏移量*/ &nbsp; &nbsp;commitAsync(Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets, OffsetCommitCallback callback)</code></pre> <p>需要注意的是，因为你可以订阅多个主题，所以 <code>offsets</code> 中必须要包含所有主题的每个分区的偏移量，示例代码如下：</p> <pre><code>try {<!-- --> &nbsp; &nbsp;while (true) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp; &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;System.out.println(record); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/*记录每个主题的每个分区的偏移量*/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition()); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(record.offset()+1, "no metaData"); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/*TopicPartition 重写过 hashCode 和 equals 方法，所以能够保证同一主题和分区的实例不会被重复添加*/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;offsets.put(topicPartition, offsetAndMetadata); &nbsp; &nbsp; &nbsp;  } &nbsp; &nbsp; &nbsp; &nbsp;/*提交特定偏移量*/ &nbsp; &nbsp; &nbsp; &nbsp;consumer.commitAsync(offsets, null); &nbsp;  }} finally {<!-- --> &nbsp; &nbsp;consumer.close();}</code></pre> <h2><span style="font-weight:bold;">五、监听分区再均衡</span></h2> <p>因为分区再均衡会导致分区与消费者的重新划分，有时候你可能希望在再均衡前执行一些操作：比如提交已经处理但是尚未提交的偏移量，关闭数据库连接等。此时可以在订阅主题时候，调用 <code>subscribe</code> 的重载方法传入自定义的分区再均衡监听器。</p> <pre><code> /*订阅指定集合内的所有主题*/subscribe(Collection&lt;String&gt; topics, ConsumerRebalanceListener listener) /*使用正则匹配需要订阅的主题*/ &nbsp; &nbsp;subscribe(Pattern pattern, ConsumerRebalanceListener listener) &nbsp; &nbsp;</code></pre> <p>代码示例如下：</p> <pre><code>Map&lt;TopicPartition, OffsetAndMetadata&gt; offsets = new HashMap&lt;&gt;();consumer.subscribe(Collections.singletonList(topic), new ConsumerRebalanceListener() {<!-- --> &nbsp; &nbsp;/*该方法会在消费者停止读取消息之后，再均衡开始之前就调用*/ &nbsp; &nbsp;@Override &nbsp; &nbsp;public void onPartitionsRevoked(Collection&lt;TopicPartition&gt; partitions) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;System.out.println("再均衡即将触发"); &nbsp; &nbsp; &nbsp; &nbsp;// 提交已经处理的偏移量 &nbsp; &nbsp; &nbsp; &nbsp;consumer.commitSync(offsets); &nbsp;  } &nbsp; &nbsp;/*该方法会在重新分配分区之后，消费者开始读取消息之前被调用*/ &nbsp; &nbsp;@Override &nbsp; &nbsp;public void onPartitionsAssigned(Collection&lt;TopicPartition&gt; partitions) {<!-- --> &nbsp;  }});try {<!-- --> &nbsp; &nbsp;while (true) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp; &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;System.out.println(record); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;TopicPartition topicPartition = new TopicPartition(record.topic(), record.partition()); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;OffsetAndMetadata offsetAndMetadata = new OffsetAndMetadata(record.offset() + 1, "no metaData"); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/*TopicPartition 重写过 hashCode 和 equals 方法，所以能够保证同一主题和分区的实例不会被重复添加*/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;offsets.put(topicPartition, offsetAndMetadata); &nbsp; &nbsp; &nbsp;  } &nbsp; &nbsp; &nbsp; &nbsp;consumer.commitAsync(offsets, null); &nbsp;  }} finally {<!-- --> &nbsp; &nbsp;consumer.close();}</code></pre> <h2><span style="font-weight:bold;">六 、退出轮询</span></h2> <p>Kafka 提供了 <code>consumer.wakeup()</code> 方法用于退出轮询，它通过抛出 <code>WakeupException</code> 异常来跳出循环。需要注意的是，在退出线程时最好显示的调用 <code>consumer.close()</code> , 此时消费者会提交任何还没有提交的东西，并向群组协调器发送消息，告知自己要离开群组，接下来就会触发再均衡 ，而不需要等待会话超时。</p> <p>下面的示例代码为监听控制台输出，当输入 <code>exit</code> 时结束轮询，关闭消费者并退出程序：</p> <pre><code>/*调用 wakeup 优雅的退出*/final Thread mainThread = Thread.currentThread();new Thread(() -&gt; {<!-- --> &nbsp; &nbsp;Scanner sc = new Scanner(System.in); &nbsp; &nbsp;while (sc.hasNext()) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;if ("exit".equals(sc.next())) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;consumer.wakeup(); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;try {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;/*等待主线程完成提交偏移量、关闭消费者等操作*/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;mainThread.join(); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;break; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  } catch (InterruptedException e) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;e.printStackTrace(); &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  } &nbsp; &nbsp; &nbsp;  } &nbsp;  }}).start();try {<!-- --> &nbsp; &nbsp;while (true) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp; &nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; rd : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;System.out.printf("topic = %s,partition = %d, key = %s, value = %s, offset = %d,\n", &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;rd.topic(), rd.partition(), rd.key(), rd.value(), rd.offset()); &nbsp; &nbsp; &nbsp;  } &nbsp;  }} catch (WakeupException e) {<!-- --> &nbsp; &nbsp;//对于 wakeup() 调用引起的 WakeupException 异常可以不必处理} finally {<!-- --> &nbsp; &nbsp;consumer.close(); &nbsp; &nbsp;System.out.println("consumer 关闭");}</code></pre> <h2><span style="font-weight:bold;">七、独立的消费者</span></h2> <p>因为 Kafka 的设计目标是高吞吐和低延迟，所以在 Kafka 中，消费者通常都是从属于某个群组的，这是因为单个消费者的处理能力是有限的。但是某些时候你的需求可能很简单，比如可能只需要一个消费者从一个主题的所有分区或者某个特定的分区读取数据，这个时候就不需要消费者群组和再均衡了， 只需要把主题或者分区分配给消费者，然后开始读取消息井提交偏移量即可。</p> <p>在这种情况下，就不需要订阅主题， 取而代之的是消费者为自己分配分区。一个消费者可以订阅主题(井加入消费者群组)，或者为自己分配分区，但不能同时做这两件事情。分配分区的示例代码如下：</p> <pre><code>List&lt;TopicPartition&gt; partitions = new ArrayList&lt;&gt;();List&lt;PartitionInfo&gt; partitionInfos = consumer.partitionsFor(topic);/*可以指定读取哪些分区 如这里假设只读取主题的 0 分区*/for (PartitionInfo partition : partitionInfos) {<!-- --> &nbsp; &nbsp;if (partition.partition()==0){<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;partitions.add(new TopicPartition(partition.topic(), partition.partition())); &nbsp;  }}// 为消费者指定分区consumer.assign(partitions);while (true) {<!-- --> &nbsp; &nbsp;ConsumerRecords&lt;Integer, String&gt; records = consumer.poll(Duration.of(100, ChronoUnit.MILLIS)); &nbsp; &nbsp;for (ConsumerRecord&lt;Integer, String&gt; record : records) {<!-- --> &nbsp; &nbsp; &nbsp; &nbsp;System.out.printf("partition = %s, key = %d, value = %s\n", &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;record.partition(), record.key(), record.value()); &nbsp;  } &nbsp; &nbsp;consumer.commitSync();}</code></pre> <h2><span style="font-weight:bold;">附录 : Kafka消费者可选属性</span></h2> <h3><span style="font-weight:bold;">1. fetch.min.byte</span></h3> <p>消费者从服务器获取记录的最小字节数。如果可用的数据量小于设置值，broker 会等待有足够的可用数据时才会把它返回给消费者。</p> <h3><span style="font-weight:bold;">2. fetch.max.wait.ms</span></h3> <p>broker 返回给消费者数据的等待时间，默认是 500ms。</p> <h3><span style="font-weight:bold;">3. max.partition.fetch.bytes</span></h3> <p>该属性指定了服务器从每个分区返回给消费者的最大字节数，默认为 1MB。</p> <h3><span style="font-weight:bold;">4. session.timeout.ms</span></h3> <p>消费者在被认为死亡之前可以与服务器断开连接的时间，默认是 3s。</p> <h3><span style="font-weight:bold;">5. auto.offset.reset</span></h3> <p>该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：</p> <ul> <li> <p>latest (默认值) ：在偏移量无效的情况下，消费者将从最新的记录开始读取数据(在消费者启动之后生成的最新记录);</p> </li> <li> <p>earliest ：在偏移量无效的情况下，消费者将从起始位置读取分区的记录。</p> </li> </ul> <h3><span style="font-weight:bold;">6. enable.auto.commit</span></h3> <p>是否自动提交偏移量，默认值是 true。为了避免出现重复消费和数据丢失，可以把它设置为 false。</p> <h3><span style="font-weight:bold;">7. client.id</span></h3> <p>客户端 id，服务器用来识别消息的来源。</p> <h3><span style="font-weight:bold;">8. max.poll.records</span></h3> <p>单次调用 <code>poll()</code> 方法能够返回的记录数量。</p> <h3><span style="font-weight:bold;">9. receive.buffer.bytes &amp; send.buffer.byte</span></h3> <p>这两个参数分别指定 TCP socket 接收和发送数据包缓冲区的大小，-1 代表使用操作系统的默认值。</p> <h2><span style="font-weight:bold;">参考资料</span></h2> <ol> <li> <p>Neha Narkhede, Gwen Shapira ,Todd Palino(著) , 薛命灯 (译) . Kafka 权威指南 . 人民邮电出版社 . 2017-12-26</p> </li> </ol> </div> </div></div> 			                        </div>

                        <div class="col-md-12 mt-5">
                                                        <p>上一个：<a href="/html/category/article-1095.htm">SpringMVC获取请求参数笔记整理_java_</a></p>
                                                        <p>下一个：<a href="/html/category/article-1097.htm">Python——if语句</a></p>
                                                    </div>

                                            </div>
                    <div class="col-md-3">
                    	<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">热门文章</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2"><a href="/html/category/article-1318.htm" title="vue项目中,如何实现excel的导入导出excel导入功能-组件封装">vue项目中,如何实现excel的导入导出excel导入功能-组件封装</a></li>
                        <li class="py-2"><a href="/html/category/article-1350.htm" title="小程序怎么自定义导航栏，导航栏放图片、设置高度">小程序怎么自定义导航栏，导航栏放图片、设置高度</a></li>
                        <li class="py-2"><a href="/html/category/article-1290.htm" title="Jmeter监控平台搭建：JMeter+InfluxDB+Grafana">Jmeter监控平台搭建：JMeter+InfluxDB+Grafana</a></li>
                        <li class="py-2"><a href="/html/category/article-1296.htm" title="Android 12(S) 图像显示系统 &#8211; SurfaceFlinger 之 VSync &#8211; 中篇（十七）">Android 12(S) 图像显示系统 &#8211; SurfaceFlinger 之 VSync &#8211; 中篇（十七）</a></li>
                        <li class="py-2"><a href="/html/category/article-1309.htm" title="sqlserver 中使用sqlcmd 执行几百M的.sql文件">sqlserver 中使用sqlcmd 执行几百M的.sql文件</a></li>
                        <li class="py-2"><a href="/html/category/article-1299.htm" title="linux信号量semaphore">linux信号量semaphore</a></li>
                        <li class="py-2"><a href="/html/category/article-1271.htm" title="c++基于模板匹配的手写数字识别（超详细）">c++基于模板匹配的手写数字识别（超详细）</a></li>
                        <li class="py-2"><a href="/html/category/article-1637.htm" title="Java基础之浅谈异常与了解断言">Java基础之浅谈异常与了解断言</a></li>
                        <li class="py-2"><a href="/html/category/article-1359.htm" title="python 数据加载工作">python 数据加载工作</a></li>
                        <li class="py-2"><a href="/html/category/article-1289.htm" title="关于MySQL支持的所有字符集的查询是什么？">关于MySQL支持的所有字符集的查询是什么？</a></li>
                    </ul>
    </div>
</div>

<div class="panel panel-default">
    <div class="panel-heading">
        <h3 class="panel-title">归纳</h3>
    </div>
    <div class="panel-body">
        <ul class="p-0 x-0" style="list-style: none;margin: 0;padding: 0;">
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">36</span> <a href="/html/date/2024-06/" title="2024-06 归档">2024-06</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-05/" title="2024-05 归档">2024-05</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">60</span> <a href="/html/date/2024-04/" title="2024-04 归档">2024-04</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">62</span> <a href="/html/date/2024-03/" title="2024-03 归档">2024-03</a></h4>
            </li>
                        <li class="py-2">
                <h4><span class="badge" style="float: right;">50</span> <a href="/html/date/2024-02/" title="2024-02 归档">2024-02</a></h4>
            </li>
                    </ul>
    </div>
</div>

                    </div>
                </div>
            </div>
        </div>
    </div>
    <!--//content-->
        <!--footer-->
    <div class="footer">
        <div class="container">
            <p>
                Myanmar Address 版权所有
                <br />
                Powered by WordPress
            </p>
        </div>
    </div>
    <script>
    $(function() {
        $('.js_to').click(function(){
            var url = $(this).data('url');
            var code = $(this).data('code');
            url += code;

            window.open(url);
        })
    });
    </script>
</body>

</html>